{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8171d754",
   "metadata": {},
   "source": [
    "## Replication of Grokking experiments \n",
    "(checking the relation between attention logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6854ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.9.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.4.0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.3.3)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (3.10.8)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (1.17.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (2025.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 3)) (2025.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (3.3.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 3)) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dac5e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b076136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed45ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.tensor(math.sin(math.exp(2*i*math.log(10,000)/d_k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ae0e846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: torch.Size([10000, 8])\n",
      "Sample 0 (Input): [2, 6, 3, 10, 5, 8, 11, 3] -> Target: 3\n"
     ]
    }
   ],
   "source": [
    "def generate_compact_dataset(num_samples=10000):\n",
    "    data_tokens = torch.arange(1, 11) \n",
    "    \n",
    "    all_inputs = []\n",
    "    all_targets = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        perm = torch.randperm(10)\n",
    "        sample_data = data_tokens[perm[:6]]\n",
    "        \n",
    "        is_relational = torch.rand(1) > 0.5\n",
    "        \n",
    "        if is_relational:\n",
    "            cmd = torch.tensor([12])\n",
    "            # Pick a key from the first 5 (so there is a neighbor at +1)\n",
    "            key_idx = torch.randint(0, 5, (1,)).item()\n",
    "            query = sample_data[key_idx].view(1)\n",
    "            target = sample_data[key_idx + 1]\n",
    "        else:\n",
    "            # POSITIONAL: Input[7] is an Index (1-6); Target is data at that index\n",
    "            cmd = torch.tensor([11])\n",
    "            idx_to_pull = torch.randint(0, 6, (1,)).item()\n",
    "            query = torch.tensor([idx_to_pull + 1])\n",
    "            target = sample_data[idx_to_pull]\n",
    "\n",
    "        full_input = torch.cat([sample_data, cmd, query])\n",
    "        \n",
    "        all_inputs.append(full_input)\n",
    "        all_targets.append(target)\n",
    "\n",
    "    return torch.stack(all_inputs), torch.stack(all_targets)\n",
    "\n",
    "# Generate the 10,000 samples\n",
    "inputs, targets = generate_compact_dataset(10000)\n",
    "\n",
    "print(f\"Dataset Shape: {inputs.shape}\") # [10000, 8]\n",
    "print(f\"Sample 0 (Input): {inputs[0].tolist()} -> Target: {targets[0].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd4f18a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = torch.zeros([8, 64])\n",
    "for j in range(3):\n",
    "    for i in range(0, 64, 2):\n",
    "        div_term = math.exp(-(math.log(10000.0) * i) / 64)\n",
    "        pe[j, i] = math.sin(j * div_term)\n",
    "        pe[j, i + 1] = math.cos(j * div_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "934908a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class embeddings(nn.Module):\n",
    "    def __init__(self, vocab_size:int = 13, d :int = 64):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, d)\n",
    "\n",
    "    def forward(self, vocab: list, pe):\n",
    "        te = self.token_emb(vocab)\n",
    "        return te+pe.to(te.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bab1d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.randperm(len(inputs))\n",
    "\n",
    "train_size = int(0.3*len(inputs))\n",
    "\n",
    "train_idx = indices[:train_size]\n",
    "test_idx = indices[train_size:]\n",
    "\n",
    "train_inputs, train_targets = inputs[train_idx], targets[train_idx]\n",
    "test_inputs,  test_targets  = inputs[test_idx],  targets[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71b41dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModule(nn.Module):\n",
    "    def __init__(self, d_k = 64):\n",
    "        super().__init__()\n",
    "        self.query_v1 = nn.Parameter(torch.randn(d_k,d_k))\n",
    "        self.key_v1 =  nn.Parameter(torch.randn(d_k,d_k))\n",
    "        self.value_v1 = nn.Parameter(torch.randn(d_k,d_k))\n",
    "\n",
    "    def forward(self, x):\n",
    "        Q1 = x @ self.query_v1\n",
    "        K1 = x @ self.key_v1\n",
    "        V1 = x @ self.value_v1\n",
    "        att1 = Q1@K1.transpose(-2, -1)/ math.sqrt(32)\n",
    "\n",
    "\n",
    "        att_soft1 = torch.softmax(att1, dim = -1)\n",
    "\n",
    "        out1 = att_soft1 @ V1\n",
    "\n",
    "        return att1, out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fdff8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelArchitecture(nn.Module):\n",
    "    def __init__(self, n :int, d_k: int, attention: AttentionModule, embedding: embeddings):\n",
    "        super().__init__()\n",
    "        self.attention = attention\n",
    "        self.embedding = embedding\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(d_k, n),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n, d_k)\n",
    "        )\n",
    "        self.unembed = nn.Linear(d_k, 13, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        att, out = self.attention(self.embedding(x, pe))\n",
    "        output = self.mlp(out)\n",
    "        logits = self.unembed(output)\n",
    "        return att, logits\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db621054",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20000\n",
    "\n",
    "attention = AttentionModule()\n",
    "embedding = embeddings()\n",
    "model = ModelArchitecture(n = 32, d_k = 64, attention = attention, embedding = embedding)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.001, weight_decay = 1)#0.3, 0.5, 1, 3, 5, 8\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fbbb41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 0 | Train Accuracy: 0.10166666656732559 | Train Loss: 3.1971819400787354 | Test Accuracy: 0.10614285618066788 | Test Loss: 2.9676084518432617 |\n",
      "| Epoch: 100 | Train Accuracy: 0.1913333386182785 | Train Loss: 2.2216250896453857 | Test Accuracy: 0.16785714030265808 | Test Loss: 2.2733142375946045 |\n",
      "| Epoch: 200 | Train Accuracy: 0.19599999487400055 | Train Loss: 2.2014172077178955 | Test Accuracy: 0.17014285922050476 | Test Loss: 2.2738969326019287 |\n",
      "| Epoch: 300 | Train Accuracy: 0.20200000703334808 | Train Loss: 2.1853559017181396 | Test Accuracy: 0.167142853140831 | Test Loss: 2.272737979888916 |\n",
      "| Epoch: 400 | Train Accuracy: 0.20999999344348907 | Train Loss: 2.168225049972534 | Test Accuracy: 0.1735714226961136 | Test Loss: 2.2743842601776123 |\n",
      "| Epoch: 500 | Train Accuracy: 0.21533332765102386 | Train Loss: 2.1487319469451904 | Test Accuracy: 0.1744285672903061 | Test Loss: 2.2710790634155273 |\n",
      "| Epoch: 600 | Train Accuracy: 0.21899999678134918 | Train Loss: 2.1374704837799072 | Test Accuracy: 0.1770000010728836 | Test Loss: 2.2729427814483643 |\n",
      "| Epoch: 700 | Train Accuracy: 0.22866666316986084 | Train Loss: 2.1273717880249023 | Test Accuracy: 0.1817142814397812 | Test Loss: 2.273219108581543 |\n",
      "| Epoch: 800 | Train Accuracy: 0.23199999332427979 | Train Loss: 2.112032175064087 | Test Accuracy: 0.17728571593761444 | Test Loss: 2.2771615982055664 |\n",
      "| Epoch: 900 | Train Accuracy: 0.24899999797344208 | Train Loss: 2.0826635360717773 | Test Accuracy: 0.18357142806053162 | Test Loss: 2.2839252948760986 |\n",
      "| Epoch: 1000 | Train Accuracy: 0.2666666805744171 | Train Loss: 2.050349473953247 | Test Accuracy: 0.19371429085731506 | Test Loss: 2.290680170059204 |\n",
      "| Epoch: 1100 | Train Accuracy: 0.2696666717529297 | Train Loss: 2.0188701152801514 | Test Accuracy: 0.19828571379184723 | Test Loss: 2.29107403755188 |\n",
      "| Epoch: 1200 | Train Accuracy: 0.2826666533946991 | Train Loss: 1.9914608001708984 | Test Accuracy: 0.2021428644657135 | Test Loss: 2.277595043182373 |\n",
      "| Epoch: 1300 | Train Accuracy: 0.3016666769981384 | Train Loss: 1.9622423648834229 | Test Accuracy: 0.212714284658432 | Test Loss: 2.2678160667419434 |\n",
      "| Epoch: 1400 | Train Accuracy: 0.3006666600704193 | Train Loss: 1.9303547143936157 | Test Accuracy: 0.21199999749660492 | Test Loss: 2.2613799571990967 |\n",
      "| Epoch: 1500 | Train Accuracy: 0.3100000023841858 | Train Loss: 1.9056240320205688 | Test Accuracy: 0.21542857587337494 | Test Loss: 2.2548117637634277 |\n",
      "| Epoch: 1600 | Train Accuracy: 0.31566667556762695 | Train Loss: 1.8862651586532593 | Test Accuracy: 0.21614286303520203 | Test Loss: 2.2473621368408203 |\n",
      "| Epoch: 1700 | Train Accuracy: 0.32766667008399963 | Train Loss: 1.8686408996582031 | Test Accuracy: 0.22357143461704254 | Test Loss: 2.242032051086426 |\n",
      "| Epoch: 1800 | Train Accuracy: 0.3343333303928375 | Train Loss: 1.854590654373169 | Test Accuracy: 0.22342857718467712 | Test Loss: 2.2356789112091064 |\n",
      "| Epoch: 1900 | Train Accuracy: 0.3346666693687439 | Train Loss: 1.8364996910095215 | Test Accuracy: 0.22499999403953552 | Test Loss: 2.228999137878418 |\n",
      "| Epoch: 2000 | Train Accuracy: 0.34166666865348816 | Train Loss: 1.8222808837890625 | Test Accuracy: 0.22871428728103638 | Test Loss: 2.218992233276367 |\n",
      "| Epoch: 2100 | Train Accuracy: 0.34200000762939453 | Train Loss: 1.8028274774551392 | Test Accuracy: 0.2314285784959793 | Test Loss: 2.205796241760254 |\n",
      "| Epoch: 2200 | Train Accuracy: 0.3526666760444641 | Train Loss: 1.7670172452926636 | Test Accuracy: 0.23771429061889648 | Test Loss: 2.175584077835083 |\n",
      "| Epoch: 2300 | Train Accuracy: 0.3526666760444641 | Train Loss: 1.7462584972381592 | Test Accuracy: 0.2394285649061203 | Test Loss: 2.161329746246338 |\n",
      "| Epoch: 2400 | Train Accuracy: 0.3630000054836273 | Train Loss: 1.7299224138259888 | Test Accuracy: 0.2418571412563324 | Test Loss: 2.1437416076660156 |\n",
      "| Epoch: 2500 | Train Accuracy: 0.39100000262260437 | Train Loss: 1.6889684200286865 | Test Accuracy: 0.2621428668498993 | Test Loss: 2.0869076251983643 |\n",
      "| Epoch: 2600 | Train Accuracy: 0.40433332324028015 | Train Loss: 1.6347380876541138 | Test Accuracy: 0.28142857551574707 | Test Loss: 2.0304465293884277 |\n",
      "| Epoch: 2700 | Train Accuracy: 0.4189999997615814 | Train Loss: 1.6072707176208496 | Test Accuracy: 0.2921428680419922 | Test Loss: 2.000424385070801 |\n",
      "| Epoch: 2800 | Train Accuracy: 0.4193333387374878 | Train Loss: 1.585098147392273 | Test Accuracy: 0.2922857105731964 | Test Loss: 1.9761430025100708 |\n",
      "| Epoch: 2900 | Train Accuracy: 0.4300000071525574 | Train Loss: 1.564676284790039 | Test Accuracy: 0.30000001192092896 | Test Loss: 1.9598420858383179 |\n",
      "| Epoch: 3000 | Train Accuracy: 0.44066667556762695 | Train Loss: 1.5480613708496094 | Test Accuracy: 0.30228570103645325 | Test Loss: 1.9522711038589478 |\n",
      "| Epoch: 3100 | Train Accuracy: 0.4426666796207428 | Train Loss: 1.5303144454956055 | Test Accuracy: 0.3061428666114807 | Test Loss: 1.939784049987793 |\n",
      "| Epoch: 3200 | Train Accuracy: 0.44433334469795227 | Train Loss: 1.5135529041290283 | Test Accuracy: 0.30628570914268494 | Test Loss: 1.9177495241165161 |\n",
      "| Epoch: 3300 | Train Accuracy: 0.44866666197776794 | Train Loss: 1.4902317523956299 | Test Accuracy: 0.3147142827510834 | Test Loss: 1.8933532238006592 |\n",
      "| Epoch: 3400 | Train Accuracy: 0.4556666612625122 | Train Loss: 1.4535564184188843 | Test Accuracy: 0.326285719871521 | Test Loss: 1.8492679595947266 |\n",
      "| Epoch: 3500 | Train Accuracy: 0.46266666054725647 | Train Loss: 1.4176645278930664 | Test Accuracy: 0.3317142724990845 | Test Loss: 1.8064420223236084 |\n",
      "| Epoch: 3600 | Train Accuracy: 0.46933332085609436 | Train Loss: 1.388580083847046 | Test Accuracy: 0.3328571319580078 | Test Loss: 1.777323842048645 |\n",
      "| Epoch: 3700 | Train Accuracy: 0.47999998927116394 | Train Loss: 1.3649388551712036 | Test Accuracy: 0.3398571312427521 | Test Loss: 1.7479745149612427 |\n",
      "| Epoch: 3800 | Train Accuracy: 0.4886666536331177 | Train Loss: 1.3375558853149414 | Test Accuracy: 0.34700000286102295 | Test Loss: 1.7092740535736084 |\n",
      "| Epoch: 3900 | Train Accuracy: 0.49399998784065247 | Train Loss: 1.308254361152649 | Test Accuracy: 0.35857143998146057 | Test Loss: 1.6821136474609375 |\n",
      "| Epoch: 4000 | Train Accuracy: 0.5109999775886536 | Train Loss: 1.2794990539550781 | Test Accuracy: 0.36414286494255066 | Test Loss: 1.6558830738067627 |\n",
      "| Epoch: 4100 | Train Accuracy: 0.5139999985694885 | Train Loss: 1.2547041177749634 | Test Accuracy: 0.3661428689956665 | Test Loss: 1.6259682178497314 |\n",
      "| Epoch: 4200 | Train Accuracy: 0.5163333415985107 | Train Loss: 1.2378309965133667 | Test Accuracy: 0.3718571364879608 | Test Loss: 1.608485221862793 |\n",
      "| Epoch: 4300 | Train Accuracy: 0.5223333239555359 | Train Loss: 1.2173082828521729 | Test Accuracy: 0.37371429800987244 | Test Loss: 1.5841819047927856 |\n",
      "| Epoch: 4400 | Train Accuracy: 0.5296666622161865 | Train Loss: 1.1954472064971924 | Test Accuracy: 0.376714289188385 | Test Loss: 1.5682648420333862 |\n",
      "| Epoch: 4500 | Train Accuracy: 0.5410000085830688 | Train Loss: 1.154468059539795 | Test Accuracy: 0.388142853975296 | Test Loss: 1.5105301141738892 |\n",
      "| Epoch: 4600 | Train Accuracy: 0.6346666812896729 | Train Loss: 0.9295685887336731 | Test Accuracy: 0.4668571352958679 | Test Loss: 1.2963316440582275 |\n",
      "| Epoch: 4700 | Train Accuracy: 0.6399999856948853 | Train Loss: 0.9049787521362305 | Test Accuracy: 0.47042858600616455 | Test Loss: 1.2691237926483154 |\n",
      "| Epoch: 4800 | Train Accuracy: 0.6460000276565552 | Train Loss: 0.8787924647331238 | Test Accuracy: 0.4838571548461914 | Test Loss: 1.2369736433029175 |\n",
      "| Epoch: 4900 | Train Accuracy: 0.6556666493415833 | Train Loss: 0.8562991619110107 | Test Accuracy: 0.492000013589859 | Test Loss: 1.221585988998413 |\n",
      "| Epoch: 5000 | Train Accuracy: 0.6696666479110718 | Train Loss: 0.8353522419929504 | Test Accuracy: 0.50128573179245 | Test Loss: 1.2083429098129272 |\n",
      "| Epoch: 5100 | Train Accuracy: 0.6806666851043701 | Train Loss: 0.8158734440803528 | Test Accuracy: 0.5049999952316284 | Test Loss: 1.189337134361267 |\n",
      "| Epoch: 5200 | Train Accuracy: 0.6856666803359985 | Train Loss: 0.8036385774612427 | Test Accuracy: 0.5038571357727051 | Test Loss: 1.1854485273361206 |\n",
      "| Epoch: 5300 | Train Accuracy: 0.6930000185966492 | Train Loss: 0.7923089861869812 | Test Accuracy: 0.5037142634391785 | Test Loss: 1.1785008907318115 |\n",
      "| Epoch: 5400 | Train Accuracy: 0.6973333358764648 | Train Loss: 0.7846730351448059 | Test Accuracy: 0.5058571696281433 | Test Loss: 1.1790485382080078 |\n",
      "| Epoch: 5500 | Train Accuracy: 0.6930000185966492 | Train Loss: 0.7796993851661682 | Test Accuracy: 0.5117142796516418 | Test Loss: 1.1766247749328613 |\n",
      "| Epoch: 5600 | Train Accuracy: 0.699999988079071 | Train Loss: 0.7751830816268921 | Test Accuracy: 0.5147143006324768 | Test Loss: 1.1740622520446777 |\n",
      "| Epoch: 5700 | Train Accuracy: 0.6970000267028809 | Train Loss: 0.7709702849388123 | Test Accuracy: 0.5167142748832703 | Test Loss: 1.170603632926941 |\n",
      "| Epoch: 5800 | Train Accuracy: 0.6993333101272583 | Train Loss: 0.767531156539917 | Test Accuracy: 0.5154285430908203 | Test Loss: 1.171324372291565 |\n",
      "| Epoch: 5900 | Train Accuracy: 0.6986666917800903 | Train Loss: 0.7654649019241333 | Test Accuracy: 0.5175714492797852 | Test Loss: 1.170943260192871 |\n",
      "| Epoch: 6000 | Train Accuracy: 0.7039999961853027 | Train Loss: 0.7504515051841736 | Test Accuracy: 0.5239999890327454 | Test Loss: 1.14262855052948 |\n",
      "| Epoch: 6100 | Train Accuracy: 0.7073333263397217 | Train Loss: 0.7364793419837952 | Test Accuracy: 0.5291428565979004 | Test Loss: 1.131746530532837 |\n",
      "| Epoch: 6200 | Train Accuracy: 0.7066666483879089 | Train Loss: 0.73095703125 | Test Accuracy: 0.5320000052452087 | Test Loss: 1.1294399499893188 |\n",
      "| Epoch: 6300 | Train Accuracy: 0.715666651725769 | Train Loss: 0.7270900011062622 | Test Accuracy: 0.5328571200370789 | Test Loss: 1.1255464553833008 |\n",
      "| Epoch: 6400 | Train Accuracy: 0.7183333039283752 | Train Loss: 0.7241770029067993 | Test Accuracy: 0.5364285707473755 | Test Loss: 1.119822382926941 |\n",
      "| Epoch: 6500 | Train Accuracy: 0.7183333039283752 | Train Loss: 0.7219988703727722 | Test Accuracy: 0.5352857112884521 | Test Loss: 1.1194785833358765 |\n",
      "| Epoch: 6600 | Train Accuracy: 0.718999981880188 | Train Loss: 0.7196664810180664 | Test Accuracy: 0.5395714044570923 | Test Loss: 1.1139923334121704 |\n",
      "| Epoch: 6700 | Train Accuracy: 0.7213333249092102 | Train Loss: 0.716523289680481 | Test Accuracy: 0.540142834186554 | Test Loss: 1.1108938455581665 |\n",
      "| Epoch: 6800 | Train Accuracy: 0.7213333249092102 | Train Loss: 0.7139794826507568 | Test Accuracy: 0.5382857322692871 | Test Loss: 1.1091121435165405 |\n",
      "| Epoch: 6900 | Train Accuracy: 0.7229999899864197 | Train Loss: 0.7102505564689636 | Test Accuracy: 0.5391428470611572 | Test Loss: 1.1045923233032227 |\n",
      "| Epoch: 7000 | Train Accuracy: 0.7233333587646484 | Train Loss: 0.7071347832679749 | Test Accuracy: 0.5424285531044006 | Test Loss: 1.1009080410003662 |\n",
      "| Epoch: 7100 | Train Accuracy: 0.7246666550636292 | Train Loss: 0.7062625288963318 | Test Accuracy: 0.5398571491241455 | Test Loss: 1.0993554592132568 |\n",
      "| Epoch: 7200 | Train Accuracy: 0.7293333411216736 | Train Loss: 0.7041136622428894 | Test Accuracy: 0.5428571701049805 | Test Loss: 1.095292091369629 |\n",
      "| Epoch: 7300 | Train Accuracy: 0.7323333621025085 | Train Loss: 0.700128436088562 | Test Accuracy: 0.5431428551673889 | Test Loss: 1.0923789739608765 |\n",
      "| Epoch: 7400 | Train Accuracy: 0.737666666507721 | Train Loss: 0.6943934559822083 | Test Accuracy: 0.5454285740852356 | Test Loss: 1.0854346752166748 |\n",
      "| Epoch: 7500 | Train Accuracy: 0.7383333444595337 | Train Loss: 0.6872236132621765 | Test Accuracy: 0.5428571701049805 | Test Loss: 1.077453851699829 |\n",
      "| Epoch: 7600 | Train Accuracy: 0.737666666507721 | Train Loss: 0.6796300411224365 | Test Accuracy: 0.5434285998344421 | Test Loss: 1.0724775791168213 |\n",
      "| Epoch: 7700 | Train Accuracy: 0.7350000143051147 | Train Loss: 0.6758894920349121 | Test Accuracy: 0.5454285740852356 | Test Loss: 1.0662990808486938 |\n",
      "| Epoch: 7800 | Train Accuracy: 0.7413333058357239 | Train Loss: 0.6634166836738586 | Test Accuracy: 0.5524285435676575 | Test Loss: 1.0500530004501343 |\n",
      "| Epoch: 7900 | Train Accuracy: 0.7459999918937683 | Train Loss: 0.6572503447532654 | Test Accuracy: 0.5548571348190308 | Test Loss: 1.043478012084961 |\n",
      "| Epoch: 8000 | Train Accuracy: 0.7476666569709778 | Train Loss: 0.654563844203949 | Test Accuracy: 0.5524285435676575 | Test Loss: 1.0389471054077148 |\n",
      "| Epoch: 8100 | Train Accuracy: 0.7459999918937683 | Train Loss: 0.6525436043739319 | Test Accuracy: 0.5532857179641724 | Test Loss: 1.035534143447876 |\n",
      "| Epoch: 8200 | Train Accuracy: 0.7480000257492065 | Train Loss: 0.6492658853530884 | Test Accuracy: 0.5544285774230957 | Test Loss: 1.031093716621399 |\n",
      "| Epoch: 8300 | Train Accuracy: 0.7513333559036255 | Train Loss: 0.6496771574020386 | Test Accuracy: 0.5531428456306458 | Test Loss: 1.0297635793685913 |\n",
      "| Epoch: 8400 | Train Accuracy: 0.7506666779518127 | Train Loss: 0.6484118700027466 | Test Accuracy: 0.5557143092155457 | Test Loss: 1.02760910987854 |\n",
      "| Epoch: 8500 | Train Accuracy: 0.746999979019165 | Train Loss: 0.6460609436035156 | Test Accuracy: 0.5591428279876709 | Test Loss: 1.0259274244308472 |\n",
      "| Epoch: 8600 | Train Accuracy: 0.7486666440963745 | Train Loss: 0.6469339728355408 | Test Accuracy: 0.5614285469055176 | Test Loss: 1.0227015018463135 |\n",
      "| Epoch: 8700 | Train Accuracy: 0.7509999871253967 | Train Loss: 0.6461509466171265 | Test Accuracy: 0.5605714321136475 | Test Loss: 1.023836374282837 |\n",
      "| Epoch: 8800 | Train Accuracy: 0.7523333430290222 | Train Loss: 0.6450541019439697 | Test Accuracy: 0.5592857003211975 | Test Loss: 1.0256993770599365 |\n",
      "| Epoch: 8900 | Train Accuracy: 0.7509999871253967 | Train Loss: 0.6426017880439758 | Test Accuracy: 0.5598571300506592 | Test Loss: 1.0266172885894775 |\n",
      "| Epoch: 9000 | Train Accuracy: 0.749666690826416 | Train Loss: 0.6446351408958435 | Test Accuracy: 0.5552856922149658 | Test Loss: 1.0293211936950684 |\n",
      "| Epoch: 9100 | Train Accuracy: 0.7519999742507935 | Train Loss: 0.643179178237915 | Test Accuracy: 0.5609999895095825 | Test Loss: 1.0278215408325195 |\n",
      "| Epoch: 9200 | Train Accuracy: 0.7523333430290222 | Train Loss: 0.6440710425376892 | Test Accuracy: 0.5624285936355591 | Test Loss: 1.026845932006836 |\n",
      "| Epoch: 9300 | Train Accuracy: 0.7516666650772095 | Train Loss: 0.6421107649803162 | Test Accuracy: 0.5615714192390442 | Test Loss: 1.0270835161209106 |\n",
      "| Epoch: 9400 | Train Accuracy: 0.7483333349227905 | Train Loss: 0.6419268250465393 | Test Accuracy: 0.5541428327560425 | Test Loss: 1.031912922859192 |\n",
      "| Epoch: 9500 | Train Accuracy: 0.7519999742507935 | Train Loss: 0.6433742046356201 | Test Accuracy: 0.5595714449882507 | Test Loss: 1.0267564058303833 |\n",
      "| Epoch: 9600 | Train Accuracy: 0.7456666827201843 | Train Loss: 0.6416035890579224 | Test Accuracy: 0.5575714111328125 | Test Loss: 1.0285823345184326 |\n",
      "| Epoch: 9700 | Train Accuracy: 0.749666690826416 | Train Loss: 0.6417270302772522 | Test Accuracy: 0.5565714240074158 | Test Loss: 1.0291703939437866 |\n",
      "| Epoch: 9800 | Train Accuracy: 0.7486666440963745 | Train Loss: 0.6425186991691589 | Test Accuracy: 0.5564285516738892 | Test Loss: 1.0291787385940552 |\n",
      "| Epoch: 9900 | Train Accuracy: 0.7576666474342346 | Train Loss: 0.6401844024658203 | Test Accuracy: 0.5622857213020325 | Test Loss: 1.023728609085083 |\n",
      "| Epoch: 10000 | Train Accuracy: 0.7590000033378601 | Train Loss: 0.6365696787834167 | Test Accuracy: 0.5587142705917358 | Test Loss: 1.023147702217102 |\n",
      "| Epoch: 10100 | Train Accuracy: 0.7573333382606506 | Train Loss: 0.6329363584518433 | Test Accuracy: 0.5571428537368774 | Test Loss: 1.0225574970245361 |\n",
      "| Epoch: 10200 | Train Accuracy: 0.7599999904632568 | Train Loss: 0.6304150819778442 | Test Accuracy: 0.553857147693634 | Test Loss: 1.0259625911712646 |\n",
      "| Epoch: 10300 | Train Accuracy: 0.7593333125114441 | Train Loss: 0.6288149952888489 | Test Accuracy: 0.5578571557998657 | Test Loss: 1.0245400667190552 |\n",
      "| Epoch: 10400 | Train Accuracy: 0.7590000033378601 | Train Loss: 0.628233015537262 | Test Accuracy: 0.5564285516738892 | Test Loss: 1.0244909524917603 |\n",
      "| Epoch: 10500 | Train Accuracy: 0.7620000243186951 | Train Loss: 0.6301937699317932 | Test Accuracy: 0.5588571429252625 | Test Loss: 1.0231603384017944 |\n",
      "| Epoch: 10600 | Train Accuracy: 0.7576666474342346 | Train Loss: 0.6276626586914062 | Test Accuracy: 0.5562857389450073 | Test Loss: 1.023826003074646 |\n",
      "| Epoch: 10700 | Train Accuracy: 0.7559999823570251 | Train Loss: 0.6270690560340881 | Test Accuracy: 0.5564285516738892 | Test Loss: 1.027427077293396 |\n",
      "| Epoch: 10800 | Train Accuracy: 0.7549999952316284 | Train Loss: 0.628219723701477 | Test Accuracy: 0.5548571348190308 | Test Loss: 1.02750825881958 |\n",
      "| Epoch: 10900 | Train Accuracy: 0.7576666474342346 | Train Loss: 0.627498209476471 | Test Accuracy: 0.5571428537368774 | Test Loss: 1.0268840789794922 |\n",
      "| Epoch: 11000 | Train Accuracy: 0.7566666603088379 | Train Loss: 0.628111720085144 | Test Accuracy: 0.5621428489685059 | Test Loss: 1.0228478908538818 |\n",
      "| Epoch: 11100 | Train Accuracy: 0.7580000162124634 | Train Loss: 0.6285502314567566 | Test Accuracy: 0.5588571429252625 | Test Loss: 1.0257011651992798 |\n",
      "| Epoch: 11200 | Train Accuracy: 0.7573333382606506 | Train Loss: 0.6296786069869995 | Test Accuracy: 0.5595714449882507 | Test Loss: 1.026471495628357 |\n",
      "| Epoch: 11300 | Train Accuracy: 0.7593333125114441 | Train Loss: 0.6279182434082031 | Test Accuracy: 0.5619999766349792 | Test Loss: 1.0223225355148315 |\n",
      "| Epoch: 11400 | Train Accuracy: 0.7580000162124634 | Train Loss: 0.627362847328186 | Test Accuracy: 0.5621428489685059 | Test Loss: 1.0217479467391968 |\n",
      "| Epoch: 11500 | Train Accuracy: 0.7546666860580444 | Train Loss: 0.6289623379707336 | Test Accuracy: 0.5617142915725708 | Test Loss: 1.0213754177093506 |\n",
      "| Epoch: 11600 | Train Accuracy: 0.7580000162124634 | Train Loss: 0.62752366065979 | Test Accuracy: 0.5614285469055176 | Test Loss: 1.0200315713882446 |\n",
      "| Epoch: 11700 | Train Accuracy: 0.7590000033378601 | Train Loss: 0.6260236501693726 | Test Accuracy: 0.5640000104904175 | Test Loss: 1.0209236145019531 |\n",
      "| Epoch: 11800 | Train Accuracy: 0.7576666474342346 | Train Loss: 0.6271604299545288 | Test Accuracy: 0.5575714111328125 | Test Loss: 1.027052879333496 |\n",
      "| Epoch: 11900 | Train Accuracy: 0.7523333430290222 | Train Loss: 0.6282354593276978 | Test Accuracy: 0.5655714273452759 | Test Loss: 1.018864631652832 |\n",
      "| Epoch: 12000 | Train Accuracy: 0.7513333559036255 | Train Loss: 0.6294673681259155 | Test Accuracy: 0.5595714449882507 | Test Loss: 1.0234295129776 |\n",
      "| Epoch: 12100 | Train Accuracy: 0.7540000081062317 | Train Loss: 0.627672553062439 | Test Accuracy: 0.5662857294082642 | Test Loss: 1.0165395736694336 |\n",
      "| Epoch: 12200 | Train Accuracy: 0.7546666860580444 | Train Loss: 0.6283263564109802 | Test Accuracy: 0.5645714402198792 | Test Loss: 1.0161128044128418 |\n",
      "| Epoch: 12300 | Train Accuracy: 0.7559999823570251 | Train Loss: 0.6261565685272217 | Test Accuracy: 0.5619999766349792 | Test Loss: 1.0193363428115845 |\n",
      "| Epoch: 12400 | Train Accuracy: 0.7536666393280029 | Train Loss: 0.6284587383270264 | Test Accuracy: 0.5628571510314941 | Test Loss: 1.0169339179992676 |\n",
      "| Epoch: 12500 | Train Accuracy: 0.7566666603088379 | Train Loss: 0.6261977553367615 | Test Accuracy: 0.5591428279876709 | Test Loss: 1.0221052169799805 |\n",
      "| Epoch: 12600 | Train Accuracy: 0.7593333125114441 | Train Loss: 0.6259825229644775 | Test Accuracy: 0.5604285597801208 | Test Loss: 1.0222959518432617 |\n",
      "| Epoch: 12700 | Train Accuracy: 0.7576666474342346 | Train Loss: 0.6254221796989441 | Test Accuracy: 0.5607143044471741 | Test Loss: 1.0226281881332397 |\n",
      "| Epoch: 12800 | Train Accuracy: 0.7570000290870667 | Train Loss: 0.6255756616592407 | Test Accuracy: 0.5611428618431091 | Test Loss: 1.0217785835266113 |\n",
      "| Epoch: 12900 | Train Accuracy: 0.7563333511352539 | Train Loss: 0.6252277493476868 | Test Accuracy: 0.5621428489685059 | Test Loss: 1.0224114656448364 |\n",
      "| Epoch: 13000 | Train Accuracy: 0.753000020980835 | Train Loss: 0.6266176700592041 | Test Accuracy: 0.5628571510314941 | Test Loss: 1.016898274421692 |\n",
      "| Epoch: 13100 | Train Accuracy: 0.7573333382606506 | Train Loss: 0.6253852248191833 | Test Accuracy: 0.5619999766349792 | Test Loss: 1.0177791118621826 |\n",
      "| Epoch: 13200 | Train Accuracy: 0.7573333382606506 | Train Loss: 0.6243685483932495 | Test Accuracy: 0.5625714063644409 | Test Loss: 1.0177973508834839 |\n",
      "| Epoch: 13300 | Train Accuracy: 0.7559999823570251 | Train Loss: 0.6240878701210022 | Test Accuracy: 0.5617142915725708 | Test Loss: 1.0187708139419556 |\n",
      "| Epoch: 13400 | Train Accuracy: 0.7543333172798157 | Train Loss: 0.6254859566688538 | Test Accuracy: 0.5640000104904175 | Test Loss: 1.015252947807312 |\n",
      "| Epoch: 13500 | Train Accuracy: 0.7543333172798157 | Train Loss: 0.6250603199005127 | Test Accuracy: 0.5624285936355591 | Test Loss: 1.0155222415924072 |\n",
      "| Epoch: 13600 | Train Accuracy: 0.7519999742507935 | Train Loss: 0.6269968152046204 | Test Accuracy: 0.5578571557998657 | Test Loss: 1.0223021507263184 |\n",
      "| Epoch: 13700 | Train Accuracy: 0.7546666860580444 | Train Loss: 0.6236250996589661 | Test Accuracy: 0.5597142577171326 | Test Loss: 1.018170952796936 |\n",
      "| Epoch: 13800 | Train Accuracy: 0.7556666731834412 | Train Loss: 0.6256495118141174 | Test Accuracy: 0.5615714192390442 | Test Loss: 1.0164717435836792 |\n",
      "| Epoch: 13900 | Train Accuracy: 0.7516666650772095 | Train Loss: 0.6250910758972168 | Test Accuracy: 0.5594285726547241 | Test Loss: 1.019347906112671 |\n",
      "| Epoch: 14000 | Train Accuracy: 0.7540000081062317 | Train Loss: 0.6252157092094421 | Test Accuracy: 0.5605714321136475 | Test Loss: 1.0176647901535034 |\n",
      "| Epoch: 14100 | Train Accuracy: 0.7570000290870667 | Train Loss: 0.6253008842468262 | Test Accuracy: 0.5614285469055176 | Test Loss: 1.0160212516784668 |\n",
      "| Epoch: 14200 | Train Accuracy: 0.7563333511352539 | Train Loss: 0.6252133250236511 | Test Accuracy: 0.5607143044471741 | Test Loss: 1.0151336193084717 |\n",
      "| Epoch: 14300 | Train Accuracy: 0.7553333044052124 | Train Loss: 0.6293139457702637 | Test Accuracy: 0.5580000281333923 | Test Loss: 1.019703984260559 |\n",
      "| Epoch: 14400 | Train Accuracy: 0.7580000162124634 | Train Loss: 0.6259440779685974 | Test Accuracy: 0.5625714063644409 | Test Loss: 1.016035556793213 |\n",
      "| Epoch: 14500 | Train Accuracy: 0.7573333382606506 | Train Loss: 0.6274460554122925 | Test Accuracy: 0.5619999766349792 | Test Loss: 1.015444278717041 |\n",
      "| Epoch: 14600 | Train Accuracy: 0.7573333382606506 | Train Loss: 0.6269726753234863 | Test Accuracy: 0.5627142786979675 | Test Loss: 1.0148380994796753 |\n",
      "| Epoch: 14700 | Train Accuracy: 0.753333330154419 | Train Loss: 0.6262786388397217 | Test Accuracy: 0.5634285807609558 | Test Loss: 1.0149877071380615 |\n",
      "| Epoch: 14800 | Train Accuracy: 0.7543333172798157 | Train Loss: 0.6287878155708313 | Test Accuracy: 0.5595714449882507 | Test Loss: 1.0199999809265137 |\n",
      "| Epoch: 14900 | Train Accuracy: 0.7559999823570251 | Train Loss: 0.6294138431549072 | Test Accuracy: 0.5632857084274292 | Test Loss: 1.0143816471099854 |\n",
      "| Epoch: 15000 | Train Accuracy: 0.7519999742507935 | Train Loss: 0.6283491849899292 | Test Accuracy: 0.5634285807609558 | Test Loss: 1.015312910079956 |\n",
      "| Epoch: 15100 | Train Accuracy: 0.7580000162124634 | Train Loss: 0.6269391775131226 | Test Accuracy: 0.5647143125534058 | Test Loss: 1.0138969421386719 |\n",
      "| Epoch: 15200 | Train Accuracy: 0.7553333044052124 | Train Loss: 0.626305103302002 | Test Accuracy: 0.5645714402198792 | Test Loss: 1.014912724494934 |\n",
      "| Epoch: 15300 | Train Accuracy: 0.7540000081062317 | Train Loss: 0.6301146149635315 | Test Accuracy: 0.5658571720123291 | Test Loss: 1.0138804912567139 |\n",
      "| Epoch: 15400 | Train Accuracy: 0.7559999823570251 | Train Loss: 0.6259397268295288 | Test Accuracy: 0.5635714530944824 | Test Loss: 1.0149352550506592 |\n",
      "| Epoch: 15500 | Train Accuracy: 0.7580000162124634 | Train Loss: 0.6255038380622864 | Test Accuracy: 0.5634285807609558 | Test Loss: 1.015863060951233 |\n",
      "| Epoch: 15600 | Train Accuracy: 0.7580000162124634 | Train Loss: 0.6261311173439026 | Test Accuracy: 0.5652857422828674 | Test Loss: 1.0146993398666382 |\n",
      "| Epoch: 15700 | Train Accuracy: 0.7573333382606506 | Train Loss: 0.6247259974479675 | Test Accuracy: 0.5628571510314941 | Test Loss: 1.015637755393982 |\n",
      "| Epoch: 15800 | Train Accuracy: 0.7513333559036255 | Train Loss: 0.6286417841911316 | Test Accuracy: 0.5597142577171326 | Test Loss: 1.019614338874817 |\n",
      "| Epoch: 15900 | Train Accuracy: 0.7580000162124634 | Train Loss: 0.6242004632949829 | Test Accuracy: 0.5634285807609558 | Test Loss: 1.0160459280014038 |\n",
      "| Epoch: 16000 | Train Accuracy: 0.7570000290870667 | Train Loss: 0.6273883581161499 | Test Accuracy: 0.5665714144706726 | Test Loss: 1.014302134513855 |\n",
      "| Epoch: 16100 | Train Accuracy: 0.7580000162124634 | Train Loss: 0.6264568567276001 | Test Accuracy: 0.566428542137146 | Test Loss: 1.0151790380477905 |\n",
      "| Epoch: 16200 | Train Accuracy: 0.7556666731834412 | Train Loss: 0.6275068521499634 | Test Accuracy: 0.5624285936355591 | Test Loss: 1.0181421041488647 |\n",
      "| Epoch: 16300 | Train Accuracy: 0.7566666603088379 | Train Loss: 0.6261552572250366 | Test Accuracy: 0.5669999718666077 | Test Loss: 1.0121314525604248 |\n",
      "| Epoch: 16400 | Train Accuracy: 0.7593333125114441 | Train Loss: 0.6269273161888123 | Test Accuracy: 0.5662857294082642 | Test Loss: 1.0102356672286987 |\n",
      "| Epoch: 16500 | Train Accuracy: 0.7603333592414856 | Train Loss: 0.624620795249939 | Test Accuracy: 0.5668571591377258 | Test Loss: 1.0102585554122925 |\n",
      "| Epoch: 16600 | Train Accuracy: 0.7553333044052124 | Train Loss: 0.6272047162055969 | Test Accuracy: 0.5631428360939026 | Test Loss: 1.0135060548782349 |\n",
      "| Epoch: 16700 | Train Accuracy: 0.7559999823570251 | Train Loss: 0.6247866749763489 | Test Accuracy: 0.5630000233650208 | Test Loss: 1.0140467882156372 |\n",
      "| Epoch: 16800 | Train Accuracy: 0.7596666812896729 | Train Loss: 0.6241295337677002 | Test Accuracy: 0.5667142868041992 | Test Loss: 1.0112556219100952 |\n",
      "| Epoch: 16900 | Train Accuracy: 0.7576666474342346 | Train Loss: 0.624274492263794 | Test Accuracy: 0.5684285759925842 | Test Loss: 1.0116019248962402 |\n",
      "| Epoch: 17000 | Train Accuracy: 0.7553333044052124 | Train Loss: 0.6259339451789856 | Test Accuracy: 0.5680000185966492 | Test Loss: 1.0113283395767212 |\n",
      "| Epoch: 17100 | Train Accuracy: 0.7556666731834412 | Train Loss: 0.6241401433944702 | Test Accuracy: 0.5631428360939026 | Test Loss: 1.0144929885864258 |\n",
      "| Epoch: 17200 | Train Accuracy: 0.7573333382606506 | Train Loss: 0.6241281032562256 | Test Accuracy: 0.5622857213020325 | Test Loss: 1.0137819051742554 |\n",
      "| Epoch: 17300 | Train Accuracy: 0.7576666474342346 | Train Loss: 0.6270752549171448 | Test Accuracy: 0.5654285550117493 | Test Loss: 1.0106085538864136 |\n",
      "| Epoch: 17400 | Train Accuracy: 0.7580000162124634 | Train Loss: 0.6272141337394714 | Test Accuracy: 0.5668571591377258 | Test Loss: 1.010922908782959 |\n",
      "| Epoch: 17500 | Train Accuracy: 0.7549999952316284 | Train Loss: 0.6286248564720154 | Test Accuracy: 0.568142831325531 | Test Loss: 1.0105416774749756 |\n",
      "| Epoch: 17600 | Train Accuracy: 0.7526666522026062 | Train Loss: 0.6308801174163818 | Test Accuracy: 0.5624285936355591 | Test Loss: 1.014853596687317 |\n",
      "| Epoch: 17700 | Train Accuracy: 0.7563333511352539 | Train Loss: 0.6253576278686523 | Test Accuracy: 0.5641428828239441 | Test Loss: 1.0138976573944092 |\n",
      "| Epoch: 17800 | Train Accuracy: 0.7556666731834412 | Train Loss: 0.6290937066078186 | Test Accuracy: 0.5667142868041992 | Test Loss: 1.0101497173309326 |\n",
      "| Epoch: 17900 | Train Accuracy: 0.7586666941642761 | Train Loss: 0.6256665587425232 | Test Accuracy: 0.5635714530944824 | Test Loss: 1.0142536163330078 |\n",
      "| Epoch: 18000 | Train Accuracy: 0.7566666603088379 | Train Loss: 0.6274802088737488 | Test Accuracy: 0.5617142915725708 | Test Loss: 1.0142713785171509 |\n",
      "| Epoch: 18100 | Train Accuracy: 0.7573333382606506 | Train Loss: 0.6265416145324707 | Test Accuracy: 0.567714273929596 | Test Loss: 1.0106092691421509 |\n",
      "| Epoch: 18200 | Train Accuracy: 0.7586666941642761 | Train Loss: 0.6244220733642578 | Test Accuracy: 0.5655714273452759 | Test Loss: 1.0122780799865723 |\n",
      "| Epoch: 18300 | Train Accuracy: 0.7523333430290222 | Train Loss: 0.624427855014801 | Test Accuracy: 0.5651428699493408 | Test Loss: 1.0126473903656006 |\n",
      "| Epoch: 18400 | Train Accuracy: 0.7580000162124634 | Train Loss: 0.6243051886558533 | Test Accuracy: 0.5671428442001343 | Test Loss: 1.011950969696045 |\n",
      "| Epoch: 18500 | Train Accuracy: 0.7580000162124634 | Train Loss: 0.6244065165519714 | Test Accuracy: 0.5661428570747375 | Test Loss: 1.0116082429885864 |\n",
      "| Epoch: 18600 | Train Accuracy: 0.7599999904632568 | Train Loss: 0.6239352226257324 | Test Accuracy: 0.5674285888671875 | Test Loss: 1.011095643043518 |\n",
      "| Epoch: 18700 | Train Accuracy: 0.7540000081062317 | Train Loss: 0.6276856064796448 | Test Accuracy: 0.5627142786979675 | Test Loss: 1.0157333612442017 |\n",
      "| Epoch: 18800 | Train Accuracy: 0.7590000033378601 | Train Loss: 0.6235225796699524 | Test Accuracy: 0.5645714402198792 | Test Loss: 1.0139068365097046 |\n",
      "| Epoch: 18900 | Train Accuracy: 0.7573333382606506 | Train Loss: 0.6229739785194397 | Test Accuracy: 0.5665714144706726 | Test Loss: 1.012296438217163 |\n",
      "| Epoch: 19000 | Train Accuracy: 0.7559999823570251 | Train Loss: 0.6256308555603027 | Test Accuracy: 0.5625714063644409 | Test Loss: 1.0152857303619385 |\n",
      "| Epoch: 19100 | Train Accuracy: 0.7573333382606506 | Train Loss: 0.6224293112754822 | Test Accuracy: 0.5655714273452759 | Test Loss: 1.013250708580017 |\n",
      "| Epoch: 19200 | Train Accuracy: 0.7566666603088379 | Train Loss: 0.6236608624458313 | Test Accuracy: 0.5634285807609558 | Test Loss: 1.0135481357574463 |\n",
      "| Epoch: 19300 | Train Accuracy: 0.7573333382606506 | Train Loss: 0.6237612366676331 | Test Accuracy: 0.5651428699493408 | Test Loss: 1.011640191078186 |\n",
      "| Epoch: 19400 | Train Accuracy: 0.7599999904632568 | Train Loss: 0.622451901435852 | Test Accuracy: 0.5640000104904175 | Test Loss: 1.0126395225524902 |\n",
      "| Epoch: 19500 | Train Accuracy: 0.7573333382606506 | Train Loss: 0.6232385635375977 | Test Accuracy: 0.5668571591377258 | Test Loss: 1.0106011629104614 |\n",
      "| Epoch: 19600 | Train Accuracy: 0.7576666474342346 | Train Loss: 0.6236461400985718 | Test Accuracy: 0.5624285936355591 | Test Loss: 1.0143184661865234 |\n",
      "| Epoch: 19700 | Train Accuracy: 0.7573333382606506 | Train Loss: 0.6217694878578186 | Test Accuracy: 0.5619999766349792 | Test Loss: 1.0174299478530884 |\n",
      "| Epoch: 19800 | Train Accuracy: 0.7593333125114441 | Train Loss: 0.6211852431297302 | Test Accuracy: 0.5648571252822876 | Test Loss: 1.0140480995178223 |\n",
      "| Epoch: 19900 | Train Accuracy: 0.7570000290870667 | Train Loss: 0.6233953237533569 | Test Accuracy: 0.5605714321136475 | Test Loss: 1.0175918340682983 |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "values = []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    att, logits = model(train_inputs)\n",
    "    predicted = logits[:, -1, :]\n",
    "    loss = criterion(predicted, train_targets)\n",
    "    train_acc = (predicted.argmax(-1) == train_targets).float().mean()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%100==0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            att_test, test_logits = model(test_inputs)\n",
    "            test_predicted = test_logits[:, -1, :]\n",
    "\n",
    "            test_loss = criterion(test_predicted, test_targets)\n",
    "            test_acc = (test_predicted.argmax(-1) == test_targets).float().mean()\n",
    "\n",
    "        temp = {\n",
    "            \"train_att\": att,\n",
    "            \"test_att\": att_test,\n",
    "            \"train_loss\": loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_acc\": test_acc\n",
    "        }\n",
    "        o = f\"| Epoch: {epoch} | Train Accuracy: {train_acc} | Train Loss: {loss} | Test Accuracy: {test_acc} | Test Loss: {test_loss} |\"\n",
    "        print(o)\n",
    "        if epoch%500==0:\n",
    "            values.append(temp)\n",
    "        with open('epoch_results_logging.log', 'a') as f:\n",
    "            f.write(f\"{o}\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ebf128",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4f83adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def tensor_handler(obj):\n",
    "    if isinstance(obj, torch.Tensor):\n",
    "        return obj.detach().cpu().tolist()\n",
    "\n",
    "with open(\"results_1.json\", 'w') as f:\n",
    "    json.dump(values, f, indent=4, default=tensor_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb1b7086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelArchitecture(\n",
       "  (attention): AttentionModule()\n",
       "  (embedding): embeddings(\n",
       "    (token_emb): Embedding(114, 128)\n",
       "  )\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  )\n",
       "  (unembed): Linear(in_features=128, out_features=114, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = AttentionModule()\n",
    "embedding = embeddings()\n",
    "model = ModelArchitecture(n=512, d_k=128, attention=attention, embedding=embedding)\n",
    "\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
