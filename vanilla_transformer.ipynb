{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8171d754",
   "metadata": {},
   "source": [
    "## Replication of Grokking experiments \n",
    "(checking the relation between attention logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6854ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.9.1)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.3.3)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.4.1)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (3.10.8)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (4.57.6)\n",
      "Requirement already satisfied: datasets in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (4.5.0)\n",
      "Requirement already satisfied: evaluate in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (0.4.6)\n",
      "Requirement already satisfied: nltk in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (3.9.2)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (2025.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 2)) (2025.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (3.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 5)) (0.36.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 5)) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 5)) (2026.1.15)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 5)) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 5)) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in ./.venv/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 6)) (23.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 6)) (0.4.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in ./.venv/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 6)) (0.28.1)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 6)) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in ./.venv/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 6)) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.venv/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (3.13.3)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 6)) (4.12.1)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 6)) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 6)) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 6)) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets->-r requirements.txt (line 6)) (0.16.0)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.12/site-packages (from nltk->-r requirements.txt (line 8)) (8.3.1)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.12/site-packages (from nltk->-r requirements.txt (line 8)) (1.5.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->transformers->-r requirements.txt (line 5)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->transformers->-r requirements.txt (line 5)) (2.6.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac5e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tokenizers import Tokenizer\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7f3a425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreeyansarora/Downloads/Polar_Representation_Attention/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'translation': {'en': 'Resumption of the session', 'fr': 'Reprise de la session'}}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('wmt14', 'fr-en')\n",
    "\n",
    "train_data = dataset['train'].select(range(10000))\n",
    "test_data = dataset['test']\n",
    "print(train_data[0])\n",
    "\n",
    "def extract_text(dataset, src=\"en\", tgt=\"fr\"):\n",
    "    for example in dataset:\n",
    "        yield example[\"translation\"][src]\n",
    "        yield example[\"translation\"][tgt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d21ef9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=37000,\n",
    "    special_tokens=[\"[PAD]\", \"[UNK]\", \"[BOS]\", \"[EOS]\"]\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(\n",
    "    extract_text(train_data),\n",
    "    trainer=trainer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "252fdda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_ID = tokenizer.token_to_id(\"[PAD]\")\n",
    "BOS_ID = tokenizer.token_to_id(\"[BOS]\")\n",
    "EOS_ID = tokenizer.token_to_id(\"[EOS]\")\n",
    "\n",
    "def tokenize_sentence(sentence, add_special_tokens=True):\n",
    "    encoding = tokenizer.encode(sentence)\n",
    "    token_ids = encoding.ids\n",
    "\n",
    "    if add_special_tokens:\n",
    "        token_ids = [BOS_ID] + token_ids + [EOS_ID]\n",
    "\n",
    "    return token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06b52fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    batch: list of dicts from wmt14 \n",
    "    Example item: {'translation': {'en': 'Hello', 'fr': 'Bonjour'}}\n",
    "    \"\"\"\n",
    "    src_list = []\n",
    "    tgt_list = []\n",
    "    \n",
    "    for item in batch:\n",
    "        en_text = item['translation']['en']\n",
    "        fr_text = item['translation']['fr']\n",
    "        \n",
    "        src_ids = tokenize_sentence(en_text)[:128] \n",
    "        tgt_ids = tokenize_sentence(fr_text)[:128]\n",
    "        \n",
    "        src_list.append(torch.tensor(src_ids, dtype=torch.long))\n",
    "        tgt_list.append(torch.tensor(tgt_ids, dtype=torch.long))\n",
    "\n",
    "    src_padded = pad_sequence(\n",
    "        src_list,\n",
    "        batch_first=True,\n",
    "        padding_value=PAD_ID\n",
    "    )\n",
    "\n",
    "    tgt_padded = pad_sequence(\n",
    "        tgt_list,\n",
    "        batch_first=True,\n",
    "        padding_value=PAD_ID\n",
    "    )\n",
    "\n",
    "    return src_padded, tgt_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9226d53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee836f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ae0e846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def generate_compact_dataset(num_samples=10000):\n",
    "#    data_tokens = torch.arange(1, 11) \n",
    "#    \n",
    "#    all_inputs = []\n",
    "#    all_targets = []\n",
    "#\n",
    "#    for _ in range(num_samples):\n",
    "#        perm = torch.randperm(10)\n",
    "#        sample_data = data_tokens[perm[:6]]\n",
    "#        \n",
    "#        is_relational = torch.rand(1) > 0.5\n",
    "#        \n",
    "#        if is_relational:\n",
    "#            cmd = torch.tensor([12])\n",
    "#            # Pick a key from the first 5 (so there is a neighbor at +1)\n",
    "#            key_idx = torch.randint(0, 5, (1,)).item()\n",
    "#            query = sample_data[key_idx].view(1)\n",
    "#            target = sample_data[key_idx + 1]\n",
    "#        else:\n",
    "#            # POSITIONAL: Input[7] is an Index (1-6); Target is data at that index\n",
    "#            cmd = torch.tensor([11])\n",
    "#            idx_to_pull = torch.randint(0, 6, (1,)).item()\n",
    "#            query = torch.tensor([idx_to_pull + 1])\n",
    "#            target = sample_data[idx_to_pull]\n",
    "#\n",
    "#        full_input = torch.cat([sample_data, cmd, query])\n",
    "#        \n",
    "#        all_inputs.append(full_input)\n",
    "#        all_targets.append(target)\n",
    "#\n",
    "#    return torch.stack(all_inputs), torch.stack(all_targets)\n",
    "#\n",
    "## Generate the 10,000 samples\n",
    "#inputs, targets = generate_compact_dataset(10000)\n",
    "#\n",
    "#print(f\"Dataset Shape: {inputs.shape}\") # [10000, 8]\n",
    "#print(f\"Sample 0 (Input): {inputs[0].tolist()} -> Target: {targets[0].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd4f18a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pe(seq_len, d_model):\n",
    "    pe = torch.zeros(seq_len, d_model)\n",
    "    position = torch.arange(0, seq_len).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    return pe.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "934908a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class embeddings(nn.Module):\n",
    "    def __init__(self, d, vocab_size=37000, max_len=512):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, d)\n",
    "        self.register_buffer('pe', get_pe(max_len, d))\n",
    "\n",
    "    def forward(self, x):\n",
    "        te = self.token_emb(x)\n",
    "        return te + self.pe[:, :x.size(1), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bab1d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices = torch.randperm(len(inputs))\n",
    "#\n",
    "#train_size = int(0.5*len(inputs))\n",
    "#\n",
    "#train_idx = indices[:train_size]\n",
    "#test_idx = indices[train_size:]\n",
    "#\n",
    "#train_inputs, train_targets = inputs[train_idx], targets[train_idx]\n",
    "#test_inputs,  test_targets  = inputs[test_idx],  targets[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71b41dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModule(nn.Module):\n",
    "    def __init__(self, d_k = 512):\n",
    "        super().__init__()\n",
    "        self.query_v1 = nn.Parameter(torch.randn(d_k,d_k))\n",
    "        self.key_v1 =  nn.Parameter(torch.randn(d_k,d_k))\n",
    "        self.value_v1 = nn.Parameter(torch.randn(d_k,d_k))\n",
    "\n",
    "    def forward(self, x):\n",
    "        Q1 = x @ self.query_v1\n",
    "        K1 = x @ self.key_v1\n",
    "        V1 = x @ self.value_v1\n",
    "        att1 = Q1@K1.transpose(-2, -1)/ math.sqrt(512)\n",
    "\n",
    "\n",
    "        att_soft1 = torch.softmax(att1, dim = -1)\n",
    "\n",
    "        out1 = att_soft1 @ V1\n",
    "\n",
    "        return out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fdff8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelArchitecture(nn.Module):\n",
    "    def __init__(self, n :int, d_k: int, attention: AttentionModule, embedding: embeddings):\n",
    "        super().__init__()\n",
    "        self.attention = attention\n",
    "        self.embedding = embedding\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(d_k, n),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n, d_k)\n",
    "        )\n",
    "        self.unembed = nn.Linear(d_k, 37000, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.attention(self.embedding(x))\n",
    "        output = self.mlp(out)\n",
    "        logits = self.unembed(output)\n",
    "        return logits\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db621054",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "attention = AttentionModule()\n",
    "embedding = embeddings(512)\n",
    "model = ModelArchitecture(n = 1024, d_k = 512, attention = attention, embedding = embedding)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.001)#0.3, 0.5, 1, 3, 5, 8\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fbbb41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| i: 0 | Train Acc: 0.1156 | Train Loss: 5.7436 | Test Acc: 0.0808 | Test Loss: 8.4606 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m     loss.backward()\n\u001b[32m     27\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     total_train_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m     total_train_acc += train_acc.item()\n\u001b[32m     32\u001b[39m calculate_bleu = (i % \u001b[32m5\u001b[39m == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (i == epochs - \u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_ID)\n",
    "model.to(DEVICE)\n",
    "\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc = 0\n",
    "    for src, tgt in train_loader:\n",
    "        src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        decoder_input  = tgt[:, :-1]  \n",
    "        decoder_target = tgt[:, 1:] \n",
    "        logits = model(decoder_input) \n",
    "\n",
    "        loss = criterion(\n",
    "            logits.reshape(-1, logits.size(-1)),\n",
    "            decoder_target.reshape(-1)\n",
    "        )\n",
    "\n",
    "        pred_tokens = logits.argmax(-1)\n",
    "        mask = decoder_target != PAD_ID\n",
    "        train_acc = ((pred_tokens == decoder_target) & mask).float().sum() / mask.sum()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "        total_train_acc += train_acc.item()\n",
    "\n",
    "    calculate_bleu = (i % 5 == 0) or (i == epochs - 1)\n",
    "\n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "    total_test_acc = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    bleu_computed = False\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (test_src, test_tgt) in enumerate(test_loader):\n",
    "            test_src, test_tgt = test_src.to(DEVICE), test_tgt.to(DEVICE)\n",
    "\n",
    "            dec_in_test  = test_tgt[:, :-1]\n",
    "            dec_tgt_test = test_tgt[:, 1:]\n",
    "\n",
    "            test_logits = model(dec_in_test)\n",
    "\n",
    "            t_loss = criterion(\n",
    "                test_logits.view(-1, test_logits.size(-1)),\n",
    "                dec_tgt_test.reshape(-1)\n",
    "            )\n",
    "            total_test_loss += t_loss.item()\n",
    "\n",
    "            test_pred = test_logits.argmax(-1)\n",
    "            test_mask = dec_tgt_test != PAD_ID\n",
    "            batch_acc = ((test_pred == dec_tgt_test) & test_mask).float().sum() / test_mask.sum()\n",
    "            total_test_acc += batch_acc.item()\n",
    "\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_train_acc  = total_train_acc / len(train_loader)\n",
    "\n",
    "    avg_test_loss = total_test_loss / len(test_loader)\n",
    "    avg_test_acc  = total_test_acc / len(test_loader)\n",
    "\n",
    "    output_str = (\n",
    "        f\"| i: {i} \"\n",
    "        f\"| Train Acc: {avg_train_acc:.4f} \"\n",
    "        f\"| Train Loss: {avg_train_loss:.4f} \"\n",
    "        f\"| Test Acc: {avg_test_acc:.4f} \"\n",
    "        f\"| Test Loss: {avg_test_loss:.4f} \"\n",
    "    )\n",
    "\n",
    "    print(output_str)\n",
    "\n",
    "    with open(\"epoch_results_logging.log\", \"a\") as f:\n",
    "        f.write(output_str + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ebf128",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
