First run with tan_pos, didnt work well

Second run with normal positional embeddings, gave way better results.

Need to evaluate using BLEU, not evaluating currently.

Test on logic and reasoning datasets, where my model is working better, and show why that happens, compared to sentence prediction. 

Try with different ablations, removing add and norm, dropout, optimizer change, scheduler change