{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0fb4894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.9.1)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.3.3)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.4.1)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (3.10.8)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (4.57.6)\n",
      "Requirement already satisfied: datasets in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (4.5.0)\n",
      "Requirement already satisfied: evaluate in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (0.4.6)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (2025.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 2)) (2025.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 4)) (3.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 5)) (0.36.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 5)) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 5)) (2026.1.15)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 5)) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 5)) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in ./.venv/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 6)) (23.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 6)) (0.4.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in ./.venv/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 6)) (0.28.1)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 6)) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in ./.venv/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 6)) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.venv/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (3.13.3)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 6)) (4.12.1)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 6)) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 6)) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets->-r requirements.txt (line 6)) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets->-r requirements.txt (line 6)) (0.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->-r requirements.txt (line 6)) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->transformers->-r requirements.txt (line 5)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->transformers->-r requirements.txt (line 5)) (2.6.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "858935be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc78dba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreeyansarora/Downloads/Polar_Representation_Attention/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'translation': {'en': 'Resumption of the session', 'fr': 'Reprise de la session'}}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('wmt14', 'fr-en')\n",
    "\n",
    "train_data = dataset['train'].select(range(10000))\n",
    "test_data = dataset['test']\n",
    "print(train_data[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7badb2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(dataset, src=\"en\", tgt=\"fr\"):\n",
    "    for example in dataset:\n",
    "        yield example[\"translation\"][src]\n",
    "        yield example[\"translation\"][tgt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac7779d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=37000,\n",
    "    special_tokens=[\"[PAD]\", \"[UNK]\", \"[BOS]\", \"[EOS]\"]\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(\n",
    "    extract_text(train_data),\n",
    "    trainer=trainer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c635571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(\"wmt14_bpe.json\")\n",
    "PAD_ID = tokenizer.token_to_id(\"[PAD]\")\n",
    "BOS_ID = tokenizer.token_to_id(\"[BOS]\")\n",
    "EOS_ID = tokenizer.token_to_id(\"[EOS]\")\n",
    "\n",
    "def tokenize_sentence(sentence, add_special_tokens=True):\n",
    "    encoding = tokenizer.encode(sentence)\n",
    "    token_ids = encoding.ids\n",
    "\n",
    "    if add_special_tokens:\n",
    "        token_ids = [BOS_ID] + token_ids + [EOS_ID]\n",
    "\n",
    "    return token_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74d374cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    batch: list of dicts from wmt14 \n",
    "    Example item: {'translation': {'en': 'Hello', 'fr': 'Bonjour'}}\n",
    "    \"\"\"\n",
    "    src_list = []\n",
    "    tgt_list = []\n",
    "    \n",
    "    for item in batch:\n",
    "        en_text = item['translation']['en']\n",
    "        fr_text = item['translation']['fr']\n",
    "        \n",
    "        src_ids = tokenize_sentence(en_text)[:128] \n",
    "        tgt_ids = tokenize_sentence(fr_text)[:128]\n",
    "        \n",
    "        src_list.append(torch.tensor(src_ids, dtype=torch.long))\n",
    "        tgt_list.append(torch.tensor(tgt_ids, dtype=torch.long))\n",
    "\n",
    "    src_padded = pad_sequence(\n",
    "        src_list,\n",
    "        batch_first=True,\n",
    "        padding_value=PAD_ID\n",
    "    )\n",
    "\n",
    "    tgt_padded = pad_sequence(\n",
    "        tgt_list,\n",
    "        batch_first=True,\n",
    "        padding_value=PAD_ID\n",
    "    )\n",
    "\n",
    "    return src_padded, tgt_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f89067ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e83b53c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33fe997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def generate_compact_dataset(num_samples=10000):\n",
    "#    data_tokens = torch.arange(1, 11) \n",
    "#    \n",
    "#    all_inputs = []\n",
    "#    all_targets = []\n",
    "#\n",
    "#    for _ in range(num_samples):\n",
    "#        perm = torch.randperm(10)\n",
    "#        sample_data = data_tokens[perm[:6]]\n",
    "#        \n",
    "#        is_relational = torch.rand(1) > 0.5\n",
    "#        \n",
    "#        if is_relational:\n",
    "#            cmd = torch.tensor([12])\n",
    "#            # Pick a key from the first 5 (so there is a neighbor at +1)\n",
    "#            key_idx = torch.randint(0, 5, (1,)).item()\n",
    "#            query = sample_data[key_idx].view(1)\n",
    "#            target = sample_data[key_idx + 1]\n",
    "#        else:\n",
    "#            # POSITIONAL: Input[7] is an Index (1-6); Target is data at that index\n",
    "#            cmd = torch.tensor([11])\n",
    "#            idx_to_pull = torch.randint(0, 6, (1,)).item()\n",
    "#            query = torch.tensor([idx_to_pull + 1])\n",
    "#            target = sample_data[idx_to_pull]\n",
    "#\n",
    "#        full_input = torch.cat([sample_data, cmd, query])\n",
    "#        \n",
    "#        all_inputs.append(full_input)\n",
    "#        all_targets.append(target)\n",
    "#\n",
    "#    return torch.stack(all_inputs), torch.stack(all_targets)\n",
    "#\n",
    "## Generate the 10,000 samples\n",
    "#inputs, targets = generate_compact_dataset(10000)\n",
    "#\n",
    "#print(f\"Dataset Shape: {inputs.shape}\") # [10000, 8]\n",
    "#print(f\"Sample 0 (Input): {inputs[0].tolist()} -> Target: {targets[0].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf638b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices = torch.randperm(len(inputs))\n",
    "#\n",
    "#train_size = int(0.5*len(inputs))\n",
    "#\n",
    "#train_idx = indices[:train_size]\n",
    "#test_idx = indices[train_size:]\n",
    "#\n",
    "#train_inputs, train_targets = inputs[train_idx], targets[train_idx]\n",
    "#test_inputs,  test_targets  = inputs[test_idx],  targets[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0818ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pe(seq_len, d_model):\n",
    "    pe = torch.zeros(seq_len, d_model)\n",
    "    position = torch.arange(0, seq_len).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    return pe.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0abdac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class embeddings(nn.Module):\n",
    "    def __init__(self, d, vocab_size=37000, max_len=512):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, d)\n",
    "        self.register_buffer('pe', get_pe(max_len, d))\n",
    "\n",
    "    def forward(self, x):\n",
    "        te = self.token_emb(x)\n",
    "        return te + self.pe[:, :x.size(1), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ef7b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class relative_matrix(nn.Module):\n",
    "    def __init__(self, e_dim: int):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(e_dim, e_dim)\n",
    "        self.bias = nn.Parameter(torch.zeros(e_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        rel = x.unsqueeze(2) - x.unsqueeze(1) \n",
    "\n",
    "        out = rel.sum(dim=2) + self.bias\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92e78e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention_matrix(nn.Module):\n",
    "    def __init__(self, e_dim):\n",
    "        super().__init__()\n",
    "        self.e_dim = e_dim\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return torch.softmax((x @ y.transpose(-2, -1))/math.sqrt(self.e_dim), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "480edfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class transformer(nn.Module):\n",
    "    def __init__(self, e_dim: int, vocab_size=37000):\n",
    "        super().__init__()\n",
    "        self.embeddings = embeddings(e_dim, vocab_size)\n",
    "        self.relative = relative_matrix(e_dim)\n",
    "        self.attention = attention_matrix(e_dim)\n",
    "        self.V = nn.Linear(e_dim, e_dim)\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(e_dim, e_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(e_dim * 2, vocab_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_emb = self.embeddings(x)\n",
    "        rel_key = self.relative(x_emb)\n",
    "        value = self.V(x_emb)\n",
    "        attn_map = self.attention(x_emb, rel_key)\n",
    "        out = attn_map @ value\n",
    "        \n",
    "        return self.output_layer(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67c5cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = transformer(512).to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c1ecc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| i: 0 | Train Acc: 0.1115 | Train Loss: 6.2793 | Test Acc: 0.1005 | Test Loss: 7.8444 |\n",
      "| i: 1 | Train Acc: 0.1372 | Train Loss: 5.6198 | Test Acc: 0.1053 | Test Loss: 7.9264 |\n",
      "| i: 2 | Train Acc: 0.1436 | Train Loss: 5.4481 | Test Acc: 0.1089 | Test Loss: 8.0106 |\n",
      "| i: 3 | Train Acc: 0.1488 | Train Loss: 5.3365 | Test Acc: 0.1089 | Test Loss: 8.0953 |\n",
      "| i: 4 | Train Acc: 0.1531 | Train Loss: 5.2588 | Test Acc: 0.1130 | Test Loss: 8.2578 |\n",
      "| i: 5 | Train Acc: 0.1564 | Train Loss: 5.1910 | Test Acc: 0.1134 | Test Loss: 8.4448 |\n",
      "| i: 6 | Train Acc: 0.1582 | Train Loss: 5.1375 | Test Acc: 0.1130 | Test Loss: 8.4144 |\n",
      "| i: 7 | Train Acc: 0.1591 | Train Loss: 5.0986 | Test Acc: 0.1139 | Test Loss: 8.4954 |\n",
      "| i: 8 | Train Acc: 0.1608 | Train Loss: 5.0582 | Test Acc: 0.1129 | Test Loss: 8.6014 |\n",
      "| i: 9 | Train Acc: 0.1619 | Train Loss: 5.0188 | Test Acc: 0.1131 | Test Loss: 8.7255 |\n",
      "| i: 10 | Train Acc: 0.1635 | Train Loss: 4.9717 | Test Acc: 0.1138 | Test Loss: 8.7552 |\n",
      "| i: 11 | Train Acc: 0.1631 | Train Loss: 4.9434 | Test Acc: 0.1158 | Test Loss: 8.8707 |\n",
      "| i: 12 | Train Acc: 0.1650 | Train Loss: 4.8978 | Test Acc: 0.1140 | Test Loss: 8.9664 |\n",
      "| i: 13 | Train Acc: 0.1663 | Train Loss: 4.8744 | Test Acc: 0.1142 | Test Loss: 9.1230 |\n",
      "| i: 14 | Train Acc: 0.1682 | Train Loss: 4.8330 | Test Acc: 0.1156 | Test Loss: 9.1271 |\n",
      "| i: 15 | Train Acc: 0.1725 | Train Loss: 4.7763 | Test Acc: 0.1160 | Test Loss: 9.1233 |\n",
      "| i: 16 | Train Acc: 0.1743 | Train Loss: 4.7469 | Test Acc: 0.1207 | Test Loss: 9.2731 |\n",
      "| i: 17 | Train Acc: 0.1788 | Train Loss: 4.7073 | Test Acc: 0.1215 | Test Loss: 9.4881 |\n",
      "| i: 18 | Train Acc: 0.1807 | Train Loss: 4.6794 | Test Acc: 0.1185 | Test Loss: 9.4736 |\n",
      "| i: 19 | Train Acc: 0.1817 | Train Loss: 4.6697 | Test Acc: 0.1217 | Test Loss: 9.4706 |\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_ID)\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc = 0\n",
    "    for src, tgt in train_loader:\n",
    "        src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        decoder_input  = tgt[:, :-1]  \n",
    "        decoder_target = tgt[:, 1:] \n",
    "        logits = model(decoder_input) \n",
    "\n",
    "        loss = criterion(\n",
    "            logits.reshape(-1, logits.size(-1)),\n",
    "            decoder_target.reshape(-1)\n",
    "        )\n",
    "\n",
    "        pred_tokens = logits.argmax(-1)\n",
    "        mask = decoder_target != PAD_ID\n",
    "        train_acc = ((pred_tokens == decoder_target) & mask).float().sum() / mask.sum()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "        total_train_acc += train_acc.item()\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "    total_test_acc = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for test_src, test_tgt in test_loader:\n",
    "            test_src, test_tgt = test_src.to(DEVICE), test_tgt.to(DEVICE)\n",
    "            \n",
    "            dec_in_test  = test_tgt[:, :-1]\n",
    "            dec_tgt_test = test_tgt[:, 1:]\n",
    "            test_logits = model(dec_in_test)\n",
    "            t_loss = criterion(\n",
    "                test_logits.reshape(-1, test_logits.size(-1)),\n",
    "                dec_tgt_test.reshape(-1)\n",
    "            )\n",
    "            total_test_loss += t_loss.item()\n",
    "\n",
    "            test_pred = test_logits.argmax(-1)\n",
    "            test_mask = dec_tgt_test != PAD_ID\n",
    "            batch_acc = ((test_pred == dec_tgt_test) & test_mask).float().sum() / test_mask.sum()\n",
    "            total_test_acc += batch_acc.item()\n",
    "    avg_test_loss = total_test_loss / len(test_loader)\n",
    "    avg_test_acc = total_test_acc / len(test_loader)\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_train_acc = total_train_acc / len(train_loader)\n",
    "    output_str = (\n",
    "        f\"| i: {i} \"\n",
    "        f\"| Train Acc: {avg_train_acc:.4f} \"\n",
    "        f\"| Train Loss: {avg_train_loss:.4f} \"\n",
    "        f\"| Test Acc: {avg_test_acc:.4f} \"\n",
    "        f\"| Test Loss: {avg_test_loss:.4f} |\"\n",
    "    )\n",
    "    print(output_str)\n",
    "    # Append string to log file\n",
    "    with open(\"epoch_results_logging.log\", \"a\") as f:\n",
    "        f.write(output_str + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3346c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
